{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Data Engineering for getting inside of Immigrants Destination Choice\n",
    "### Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The goal of this project is to create an ETL pipeline using I94 immigration data, city temperature data and U.S. demographics states data to form a database that is optimized for queries on immigration events. This database can be used to answer questions relating immigration behavior to destination demographics and/or temperature. For example do people tend to immigrate to warmer places? or how state divercity does play role on immigrants destination choice.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Wrangling the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession, SQLContext, GroupedData\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from i94_label import immigration_codes, state_abbrev, abbrev_state, i94_port, country_udf,\\\n",
    "state_udf, abbrev_state_udf, city_code_udf, state_code_udf, i94_model, i94_visa, arr_udf, visa_udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "For this project, 3 different data set has been used and pull data from all sources and create fact and dimension tables to show movement of immigration.\n",
    "I94 immigration data, temperature data and U.S. cities demographics used for dimensional tables. Spark will be used to process the data.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "The I94 immigration [data](https://travel.trade.gov/research/reports/i94/historical/2016.html) comes from the US National Tourism and Trade Office. It is provided in SAS7BDAT [format](https://cran.r-project.org/web/packages/sas7bdat/vignettes/sas7bdat.pdf) which is a binary database storage format. Some relevant attributes include:\n",
    "* i94yr = 4 digit year\n",
    "* i94mon = numeric month\n",
    "* i94cit = 3 digit code of origin city\n",
    "* i94port = 3 character code of entering USA city\n",
    "* i94mode = arriving model\n",
    "* depdate = departure date from the USA\n",
    "* i94visa = type of  visa\n",
    "\n",
    "The temperature [data](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) comes from Kaggle. It is provided in csv format. Some relevant attributes include:\n",
    "* AverageTemperature = average temperature (Celsius)\n",
    "* City\n",
    "* Country\n",
    "* Latitude\n",
    "* Longitude \n",
    "\n",
    "U.S. City Demographic Data: comes from [OpenSoft](https://public.opendatasoft.com/) and includes data by city, state, age, population, veteran status and race. Some relevant attributes include:\n",
    "* City\n",
    "* State\n",
    "* Total number of population\n",
    "* Race and their number\n",
    "* Number of Veterans\n",
    "* Number of Foreign born"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Wrangling the Data\n",
    "\n",
    "After accessing and exploring on datasets, for each datasets some steps applied and needed columns for data model selected in final step.\n",
    "\n",
    "#### Accessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Spark session with SAS7BDAT jar\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Build SQL context object\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data presented in workspace\n",
    "demog=spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \";\").load(\"us-cities-demographics.csv\")\n",
    "airport=spark.read.format(\"csv\").option(\"header\", \"true\").load(\"airport-codes_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reading I94 and Temperature dataset\n",
    "df_i94 =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_feb16_sub.sas7bdat')\n",
    "temp =spark.read.format(\"csv\").option(\"header\", \"true\").load(\"../../data2/GlobalLandTemperaturesByCity.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Data\n",
    "##### 1. Temperature Dataset:\n",
    "    - Removing null rows\n",
    "    - Filtering on country by United State\n",
    "    - Filtering on last year on dataset, 2013\n",
    "    - Adding state name baseed on city name\n",
    "    - Selecting needed columns and change their names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean temperature data\n",
    "\n",
    "# Valid City and add their State column     \n",
    "@udf\n",
    "def get_state(city):\n",
    "    '''\n",
    "    This function take City from Tempreture dataset and check the city name by \"i94 valid\" list and\n",
    "    return corresponded state:\n",
    "    \n",
    "    Input: City name\n",
    "    Outpot: Corresponding i94port and State\n",
    "\n",
    "    '''\n",
    "    for key in i94_port:\n",
    "        if city.lower() in i94_port[key].rsplit()[0].lower():\n",
    "            return i94_port[key].rsplit()[-1]\n",
    "        \n",
    "\n",
    "# Add State column\n",
    "temp= temp.withColumn(\"state_code\", get_state(temp[\"City\"]))\\\n",
    ".filter(temp.Country == \"United States\")\\\n",
    ".filter(year(temp[\"dt\"]) == 2013)\\\n",
    ".withColumn(\"month\" ,month(temp[\"dt\"]))\\\n",
    ".withColumn(\"year\" ,year(temp[\"dt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-------+-------------+--------+---------+----------+-----+----+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty|   City|      Country|Latitude|Longitude|state_code|month|year|\n",
      "+----------+------------------+-----------------------------+-------+-------------+--------+---------+----------+-----+----+\n",
      "|2013-01-01|              6.32|                        0.267|Abilene|United States|  32.95N|  100.53W|      null|    1|2013|\n",
      "+----------+------------------+-----------------------------+-------+-------------+--------+---------+----------+-----+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show Result\n",
    "temp.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp= temp.filter(temp['state_code'] != 'null').withColumn(\"state\", abbrev_state_udf(temp['state_code']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------------+--------+---------+----------+-----+----+-----+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|      Country|Latitude|Longitude|state_code|month|year|state|\n",
      "+----------+------------------+-----------------------------+-----+-------------+--------+---------+----------+-----+----+-----+\n",
      "|2013-01-01|            -1.086|                         0.22|Akron|United States|  40.99N|   80.95W|        OH|    1|2013| Ohio|\n",
      "+----------+------------------+-----------------------------+-----+-------------+--------+---------+----------+-----+----+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show Result\n",
    "temp.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Selecting needed columns\n",
    "new_temp= temp.select(\"year\",\"month\",round(col(\"AverageTemperature\"),1).alias(\"avg_temp_celsius\"),\"state_code\", \"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------------+----------+----------+\n",
      "|year|month|avg_temp_celsius|state_code|     state|\n",
      "+----+-----+----------------+----------+----------+\n",
      "|2013|    1|            -1.1|        OH|      Ohio|\n",
      "|2013|    2|            -2.2|        OH|      Ohio|\n",
      "|2013|    3|             1.3|        OH|      Ohio|\n",
      "|2013|    4|             9.7|        OH|      Ohio|\n",
      "|2013|    5|            16.8|        OH|      Ohio|\n",
      "|2013|    6|            20.6|        OH|      Ohio|\n",
      "|2013|    7|            23.0|        OH|      Ohio|\n",
      "|2013|    8|            21.0|        OH|      Ohio|\n",
      "|2013|    9|            17.8|        OH|      Ohio|\n",
      "|2013|    1|            -2.0|        NM|New Mexico|\n",
      "+----+-----+----------------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show Result\n",
    "new_temp.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2. I94 Immigration Data\n",
    "    - Removing null rows\n",
    "    - Validating destination city, port, visa and arriving model\n",
    "    - Changing arriving port and destination to complete city and state name\n",
    "    - Selecting needed columns for data model and change names\n",
    "> **Note**: in some rows arriving port state were different from destination address state. In this case, difference has been assumed is true and passenger select different entering point than final address\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean I94 immigration data\n",
    "i94_data=df_i94.filter(df_i94.i94addr.isNotNull())\\\n",
    ".filter(df_i94.i94res.isNotNull())\\\n",
    ".filter(col(\"i94addr\").isin(list(abbrev_state.keys())))\\\n",
    ".filter(col(\"i94port\").isin(list(i94_port.keys())))\\\n",
    ".filter(col(\"i94visa\").cast(\"integer\").isin(list(i94_visa.keys())))\\\n",
    ".filter(col(\"i94mode\").cast(\"integer\").isin(list(i94_model.keys())))\\\n",
    ".withColumn(\"origin_country\",country_udf(df_i94[\"i94cit\"]))\\\n",
    ".withColumn(\"dest_state_name\",abbrev_state_udf(df_i94[\"i94addr\"]))\\\n",
    ".withColumn(\"i94yr\",col(\"i94yr\").cast(\"integer\"))\\\n",
    ".withColumn(\"i94mon\",col(\"i94mon\").cast(\"integer\"))\\\n",
    ".withColumn(\"city_port_name\",city_code_udf(df_i94[\"i94port\"]))\\\n",
    ".withColumn(\"state_port_name\",state_code_udf(df_i94[\"i94port\"]))\\\n",
    ".withColumn(\"i94mode\",arr_udf(col(\"i94mode\").cast(\"integer\")))\\\n",
    ".withColumn(\"i94visa\",visa_udf(col(\"i94visa\").cast(\"integer\")))\n",
    "\n",
    "new_i94=i94_data.select(col(\"i94yr\").alias(\"year\"),col(\"i94mon\").alias(\"month\"),\\\n",
    "                        \"origin_country\",col(\"i94mode\").alias(\"arriving_model\"),\\\n",
    "                        col(\"i94visa\").alias(\"visa_type\"),\n",
    "                        \"city_port_name\",\"state_port_name\",\\\n",
    "                        col(\"i94addr\").alias(\"state_code\"),\"dest_state_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+--------------+--------------+---------+--------------+---------------+----------+---------------+\n",
      "|year|month|origin_country|arriving_model|visa_type|city_port_name|state_port_name|state_code|dest_state_name|\n",
      "+----+-----+--------------+--------------+---------+--------------+---------------+----------+---------------+\n",
      "|2016|    2|       ALBANIA|           Air|  Student|      ATLANTA,|             GA|        MI|       Michigan|\n",
      "|2016|    2|       ALBANIA|           Air| Pleasure|      CHICAGO,|             IL|        IL|       Illinois|\n",
      "|2016|    2|       ALBANIA|           Air| Pleasure|      CHICAGO,|             IL|        IL|       Illinois|\n",
      "|2016|    2|       ALBANIA|           Air| Pleasure|      CHICAGO,|             IL|        AZ|        Arizona|\n",
      "|2016|    2|       ALBANIA|           Air| Pleasure|      CHICAGO,|             IL|        IL|       Illinois|\n",
      "|2016|    2|       ALBANIA|           Air| Pleasure|      CHICAGO,|             IL|        IL|       Illinois|\n",
      "|2016|    2|       ALBANIA|           Air| Pleasure|       TUCSON,|             AZ|        MI|       Michigan|\n",
      "|2016|    2|       ALBANIA|           Air| Pleasure|       TUCSON,|             AZ|        MI|       Michigan|\n",
      "|2016|    2|       ALBANIA|           Air| Pleasure|       TUCSON,|             AZ|        MI|       Michigan|\n",
      "|2016|    2|       ALBANIA|           Air| Pleasure|       TUCSON,|             AZ|        MI|       Michigan|\n",
      "+----+-----+--------------+--------------+---------+--------------+---------------+----------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_i94.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 3. US Cities Demographic Data:\n",
    "    - Remove nulls\n",
    "    - Calculate percentage of population related columns\n",
    "    - Pivot on `Race` diversity\n",
    "    - Organize  by state and put average for numeric columns\n",
    "    - Select needed columns for data model and make final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            City|        State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|   California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|   New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demog.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demog_1= demog\\\n",
    ".withColumn(\"pct_veterans\",demog[\"Number of Veterans\"]/demog[\"Total Population\"]*100)\\\n",
    ".withColumn(\"pct_foreign_born\",demog[\"Foreign-born\"]/demog[\"Total Population\"]*100)\\\n",
    ".withColumn(\"pct_race\",demog[\"Count\"]/demog[\"Total Population\"]*100)\\\n",
    ".orderBy(\"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Select columns with new calculated percentages and state names.\n",
    "demog_2= demog_1.select(\"State\",\\\n",
    "                         col(\"State Code\").alias(\"state_code\"),\\\n",
    "                         \"pct_veterans\",\\\n",
    "                         \"pct_foreign_born\",\\\n",
    "                         \"Race\",\\\n",
    "                         \"pct_race\"\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------------+------------------+--------------------+------------------+\n",
      "|  State|state_code|      pct_veterans|  pct_foreign_born|                Race|          pct_race|\n",
      "+-------+----------+------------------+------------------+--------------------+------------------+\n",
      "|Alabama|        AL| 7.455654931052018|4.6548612565184015|American Indian a...|0.6366346604448964|\n",
      "|Alabama|        AL| 6.144463601039603|3.7230127891716633|American Indian a...|1.4492679035536913|\n",
      "|Alabama|        AL| 3.708637556183774| 4.785535601700258|               Asian| 2.779190140128943|\n",
      "|Alabama|        AL| 7.455654931052018|4.6548612565184015|               White|36.665071340970954|\n",
      "|Alabama|        AL| 3.708637556183774| 4.785535601700258|  Hispanic or Latino| 2.516829709776485|\n",
      "|Alabama|        AL| 8.797339171081992| 6.710767050562094|  Hispanic or Latino| 5.756845077572257|\n",
      "|Alabama|        AL| 7.455654931052018|4.6548612565184015|  Hispanic or Latino|3.3142891328407766|\n",
      "|Alabama|        AL| 7.455654931052018|4.6548612565184015|Black or African-...|60.502727009861104|\n",
      "|Alabama|        AL| 6.144463601039603|3.7230127891716633|               Asian|2.8398651604436322|\n",
      "|Alabama|        AL|6.1476611248377235| 3.842520857471232|               Asian|0.6979633429652274|\n",
      "|Alabama|        AL| 8.797339171081992| 6.710767050562094|Black or African-...|32.552322937487446|\n",
      "|Alabama|        AL|  5.68017067622202| 9.699548556677943|  Hispanic or Latino| 4.042951944270913|\n",
      "|Alabama|        AL|  5.68017067622202| 9.699548556677943|               Asian| 5.609448484777048|\n",
      "|Alabama|        AL| 3.708637556183774| 4.785535601700258|American Indian a...|0.2654111330309748|\n",
      "|Alabama|        AL| 9.378701729447998| 2.515695332859512|  Hispanic or Latino| 2.523098791755508|\n",
      "|Alabama|        AL| 8.797339171081992| 6.710767050562094|               White|  64.4605899087323|\n",
      "|Alabama|        AL|6.1476611248377235| 3.842520857471232|American Indian a...|  0.61374243291409|\n",
      "|Alabama|        AL|  5.68017067622202| 9.699548556677943|               White| 72.92518770848314|\n",
      "|Alabama|        AL| 8.797339171081992| 6.710767050562094|               Asian|3.4719798639973773|\n",
      "|Alabama|        AL| 9.378701729447998| 2.515695332859512|               White| 64.43378346363421|\n",
      "+-------+----------+------------------+------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demog_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Pivot the Race column\n",
    "pivot_demog= demog_2.groupBy(\"State\",\"state_code\",\"pct_veterans\",\\\n",
    "                               \"pct_foreign_born\").pivot(\"Race\").avg(\"pct_race\")\n",
    "\n",
    "# Change the header name of the race fields\n",
    "pivot_demog= pivot_demog.select(\"State\",\"state_code\",\"pct_veterans\",\"pct_foreign_born\",\\\n",
    "                               col(\"American Indian and Alaska Native\").alias(\"native_american\"),\\\n",
    "                               col(\"Asian\"),col(\"Black or African-American\").alias(\"Black\"),\\\n",
    "                               col(\"Hispanic or Latino\").alias(\"hispanic_latino\"),\"White\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|  State|state_code|      pct_veterans|  pct_foreign_born|   native_american|             Asian|             Black|   hispanic_latino|             White|\n",
      "+-------+----------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|Alabama|        AL|  5.68017067622202| 9.699548556677943|              null| 5.609448484777048|21.441789742924833| 4.042951944270913| 72.92518770848314|\n",
      "|Alabama|        AL| 7.455654931052018|4.6548612565184015|0.6366346604448964| 3.249479026452494|60.502727009861104|3.3142891328407766|36.665071340970954|\n",
      "|Alabama|        AL| 8.797339171081992| 6.710767050562094|0.9280116754973191|3.4719798639973773|32.552322937487446| 5.756845077572257|  64.4605899087323|\n",
      "|Alabama|        AL|6.1476611248377235| 3.842520857471232|  0.61374243291409|0.6979633429652274|  73.5118258255743| 4.159861524072755|24.069498536603522|\n",
      "|Alabama|        AL| 9.378701729447998| 2.515695332859512|0.9713338071547027|1.7398128405591091| 34.41571902392798| 2.523098791755508| 64.43378346363421|\n",
      "+-------+----------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivot_demog.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculating average of each column per state.\n",
    "demog_avg= pivot_demog.groupBy(\"State\",\"state_code\").avg(\"pct_veterans\",\"pct_foreign_born\",\\\n",
    "                                                        \"native_american\",\"Asian\",\"Black\",\"hispanic_latino\",\\\n",
    "                                                        \"White\").orderBy(\"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Round the percentages and rename column names\n",
    "new_demog= demog_avg.select(col(\"State\").alias(\"state\"),\\\n",
    "                             \"state_code\",\\\n",
    "                             round(col(\"avg(pct_veterans)\"),1).alias(\"pct_veterans\"),\\\n",
    "                             round(col(\"avg(pct_foreign_born)\"),1).alias(\"pct_foreign_born\"),\\\n",
    "                             round(col(\"avg(native_american)\"),1).alias(\"native_american\"),\\\n",
    "                             round(col(\"avg(Asian)\"),1).alias(\"asian\"),\\\n",
    "                             round(col(\"avg(hispanic_latino)\"),1).alias(\"hispanic_latino\"),\\\n",
    "                             round(col(\"avg(Black)\"),1).alias(\"black\"),\\\n",
    "                             round(col(\"avg(White)\"),1).alias('white')\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------------+----------------+---------------+-----+---------------+-----+-----+\n",
      "|               state|state_code|pct_veterans|pct_foreign_born|native_american|asian|hispanic_latino|black|white|\n",
      "+--------------------+----------+------------+----------------+---------------+-----+---------------+-----+-----+\n",
      "|             Alabama|        AL|         6.8|             5.1|            0.8|  2.9|            3.6| 45.0| 52.0|\n",
      "|              Alaska|        AK|         9.2|            11.1|           12.2| 12.3|            9.1|  7.7| 71.2|\n",
      "|             Arizona|        AZ|         6.6|            12.6|            2.8|  5.1|           28.8|  6.0| 82.7|\n",
      "|            Arkansas|        AR|         5.2|            10.7|            1.8|  4.1|           14.2| 21.8| 68.0|\n",
      "|          California|        CA|         4.1|            27.6|            1.7| 17.9|           37.8|  7.5| 62.7|\n",
      "|            Colorado|        CO|         6.2|             9.6|            2.0|  4.9|           22.2|  4.2| 88.0|\n",
      "|         Connecticut|        CT|         2.9|            25.2|            1.3|  5.3|           34.8| 24.3| 59.6|\n",
      "|            Delaware|        DE|         4.3|             4.6|            0.6|  1.7|            7.7| 61.4| 33.0|\n",
      "|District of Columbia|        DC|         3.9|            14.1|            0.9|  5.2|           10.6| 48.9| 42.5|\n",
      "|             Florida|        FL|         5.7|            24.9|            0.9|  4.0|           28.4| 23.5| 70.4|\n",
      "|             Georgia|        GA|         6.1|            10.3|            0.9|  6.5|            7.7| 41.5| 51.4|\n",
      "|              Hawaii|        HI|         6.6|            28.7|            1.6| 68.3|            7.0|  3.3| 31.3|\n",
      "|               Idaho|        ID|         6.3|             7.5|            1.6|  3.0|           13.6|  1.9| 92.3|\n",
      "|            Illinois|        IL|         3.9|            20.9|            0.8| 10.5|           22.8| 14.3| 66.8|\n",
      "|             Indiana|        IN|         4.7|             7.4|            0.9|  4.9|            9.6| 21.7| 72.8|\n",
      "|                Iowa|        IA|         5.2|             8.8|            1.3|  6.0|            8.5|  9.7| 83.2|\n",
      "|              Kansas|        KS|         5.4|             9.8|            2.2|  5.6|           13.2| 11.7| 82.0|\n",
      "|            Kentucky|        KY|         5.8|             7.6|            0.9|  3.7|            5.8| 20.5| 76.7|\n",
      "|           Louisiana|        LA|         5.9|             7.3|            0.6|  2.9|            8.6| 39.9| 56.8|\n",
      "|               Maine|        ME|         5.5|            13.8|            1.0|  5.5|            3.0|  8.6| 89.3|\n",
      "+--------------------+----------+------------+----------------+---------------+-----+---------------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_demog.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "\n",
    "#### Conceptual Data Model\n",
    "During `Wrangling process`, an schema of data model, based on objective directions of this analysis project, was in mind and so selected columns rely on.\n",
    "`Star Schema` has been selected to connect fact and dimensional tables.\n",
    "\n",
    "#### Mapping Out Data Pipelines\n",
    "For mapping data, following step has been done:\n",
    "* Dimension tables create from cleans data.\n",
    "* Fact table created as a SQL query with joins to dimension tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### Data Model and Data Dictionary\n",
    "Data model, developed based on final datasets on following items:\n",
    "\n",
    "1. **U.S. Demographic by State**\n",
    "`\n",
    "state: string (nullable = true)-Full state name\n",
    "state_code: string (nullable = true)-Abbreviated state code\n",
    "pct_veterans: double (nullable = true)-% Avg Veteran population per state\n",
    "pct_foreign_born: double (nullable = true)-% Avg Foreign-Born population per state\n",
    "native_american: double (nullable = true)-% Avg Native American population per state\n",
    "asian: double (nullable = true)-% Avg Asian population per state\n",
    "hispanic_latino: double (nullable = true)% Avg Hispanic or Latino population per state\n",
    "black: double (nullable = true)-% Avg Black population per state\n",
    "white: double (nullable = true)-% Avg White population per state`\n",
    "\n",
    "2. **Immigration Data by State with Origin**\n",
    "`year: integer (nullable = true)-Year of immigration\n",
    "month: integer (nullable = true)-Month of immigration\n",
    "origin_country: string (nullable = true)-Country of origin\n",
    "arriving_model: string (nullable = true)-How immigrant entered (Air, Land, Sea)\n",
    "visa_type: string (nullable = true)-Type of immigrant visa\n",
    "city_port_name: string (nullable = true)-City port name\n",
    "state_port_name: string (nullable = true)-State port name\n",
    "state_code: string (nullable = true)-Abbreviated destination state code\n",
    "dest_state_name: string (nullable = true)-State destination name\n",
    "`\n",
    "3. **Temperature Data by State**\n",
    "`\n",
    "year: integer (nullable = true)- Temperature Year\n",
    "month: integer (nullable = true)- Temperature Month\n",
    "avg_temp_celsius: double (nullable = true)- Avg Temperature in Celsius per State\n",
    "state_code: string (nullable = true)-Abbreviated State Code\n",
    "State: string (nullable = true)-State Name\n",
    "`\n",
    "4. **Fact Table**\n",
    "`\n",
    "year: integer (nullable = true)-Year from immigration table\n",
    "immig_month: integer (nullable = true)-Month from immigration table\n",
    "immig_from: string (nullable = true)-Country of Origin from immigration table\n",
    "immig_state: string (nullable = true)-State immigrated to from immigration table\n",
    "immig_state_count: long (nullable = false)-Total count of people immigrated per state from immigration table\n",
    "pct_foreign_born: double (nullable = true)-Avg % foreign born from Demographic table\n",
    "native_american: double (nullable = true)-Avg % Native American population from Demographic table\n",
    "asian: double (nullable = true)-Avg % Asian population from Demographic table\n",
    "hispanic_latino: double (nullable = true)-% Avg Hispanic or Latino population per state from Demographic table\n",
    "black: double (nullable = true)-% Avg Black population per state from Demographic table\n",
    "white: double (nullable = true)-% Avg White population per state from Demographic table\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Dimension tables\n",
    "new_i94.createOrReplaceTempView(\"immigration\")\n",
    "new_demog.createOrReplaceTempView(\"demographics\")\n",
    "new_temp.createOrReplaceTempView(\"temperature\")\n",
    "\n",
    "# Allow unlimited time for SQL joins and parquet writes.\n",
    "sqlContext.setConf(\"spark.sql.autoBroadcastJoinThreshold\", \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This query will build the fact table by joining to the dimension tables above.\n",
    "# We are counting how many people immigrated to each state in the U.S.\n",
    "immigration_to_state = spark.sql(\"\"\"\n",
    "SELECT \n",
    "m.year,\n",
    "m.month AS immig_month,\n",
    "m.origin_country AS immig_from,\n",
    "m.dest_state_name AS immig_state,\n",
    "m.arriving_model,\n",
    "m.visa_type,\n",
    "t.avg_temp_celsius,\n",
    "d.pct_foreign_born,\n",
    "d.native_american,\n",
    "d.asian,\n",
    "d.hispanic_latino,\n",
    "d.black,\n",
    "d.white\n",
    "    \n",
    "FROM immigration m JOIN temperature t ON (m.state_code=t.state_code) AND (m.month=t.month) \n",
    "JOIN demographics d ON (d.state_code=t.state_code)\n",
    "                                    \n",
    "GROUP BY m.year,\\\n",
    "m.month,\\\n",
    "m.origin_country,\\\n",
    "m.dest_state_name,\\\n",
    "m.arriving_model,\\\n",
    "m.visa_type,\\\n",
    "t.avg_temp_celsius,\\\n",
    "d.pct_foreign_born,\\\n",
    "d.native_american,\\\n",
    "d.asian,\\\n",
    "d.hispanic_latino,\\\n",
    "d.white,\\\n",
    "d.black\n",
    "                                    \n",
    "ORDER BY m.origin_country\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- immig_month: integer (nullable = true)\n",
      " |-- immig_from: string (nullable = true)\n",
      " |-- immig_state: string (nullable = true)\n",
      " |-- arriving_model: string (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      " |-- avg_temp_celsius: double (nullable = true)\n",
      " |-- pct_foreign_born: double (nullable = true)\n",
      " |-- native_american: double (nullable = true)\n",
      " |-- asian: double (nullable = true)\n",
      " |-- hispanic_latino: double (nullable = true)\n",
      " |-- black: double (nullable = true)\n",
      " |-- white: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_to_state.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Quality Checks\n",
    "During wrangling process, some part data quality has applied in removing null rows. Now the data quality check will ensure there are adequate number of entries in each table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def quality_check(df, description):\n",
    "    '''\n",
    "    Input: Spark dataframe, description of Spark datafram\n",
    "    \n",
    "    Output: Print outcome of data quality check\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    result = df.count()\n",
    "    if result == 0:\n",
    "        print(\"Data quality check failed for {} with zero records\".format(description))\n",
    "    else:\n",
    "        print(\"Data quality check passed for {} with {} records\".format(description, result))\n",
    "    return 0\n",
    "\n",
    "# Perform data quality check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for immigration table with 2241338 records\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_check(new_i94, \"immigration table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for temperature table with 729 records\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_check(new_temp, \"temperature table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for demographic table with 49 records\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_check(new_demog, \"demographic table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "\n",
    "Spark was chosen since it can easily handle multiple file formats (including SAS) containing large amounts of data. Spark SQL was chosen to process the large input files into dataframes and manipulated via standard SQL join operations to form additional tables.\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "\n",
    "The data should be updated monthly in conjunction with the current raw file format.\n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    "\n",
    ">The data was increased by 100x.\n",
    " \n",
    "If the data was increased by 100x, we would no longer process the data as a single batch job. We could perhaps do incremental updates. We could also consider moving Spark to cluster mode using a cluster manager such as Yarn.  \n",
    " \n",
    ">The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " \n",
    "If the data needs to populate a dashboard daily to meet an SLA then we could use a scheduling tool such as [Airflow](https://airflow.apache.org) to run the ETL pipeline overnight.\n",
    " \n",
    ">The database needed to be accessed by 100+ people.\n",
    " \n",
    "If the database needed to be accessed by 100+ people, we could consider publishing the parquet files to HDFS and giving read access to users that need it. Using cloud services like AWS and Azure are other options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
